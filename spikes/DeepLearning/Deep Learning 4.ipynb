{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape([-1, 28*28]) / 255\n",
    "x_test = x_test.reshape([-1, 28*28]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28,), init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(10, init=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"uniform\")`\n",
      "  import sys\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 2.3006 - acc: 0.1128 - val_loss: 2.2988 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.2970 - acc: 0.1124 - val_loss: 2.2942 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 2.2881 - acc: 0.1138 - val_loss: 2.2752 - val_acc: 0.1466\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.1078 - acc: 0.3009 - val_loss: 1.6799 - val_acc: 0.3797\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 1.2312 - acc: 0.5806 - val_loss: 0.8878 - val_acc: 0.7057\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.7851 - acc: 0.7534 - val_loss: 0.6723 - val_acc: 0.8061\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.5934 - acc: 0.8359 - val_loss: 0.5135 - val_acc: 0.8588\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.4860 - acc: 0.8650 - val_loss: 0.4401 - val_acc: 0.8749\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.4278 - acc: 0.8800 - val_loss: 0.3921 - val_acc: 0.8902\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3812 - acc: 0.8937 - val_loss: 0.3660 - val_acc: 0.8970\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.3390 - acc: 0.9052 - val_loss: 0.3188 - val_acc: 0.9113\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.3003 - acc: 0.9176 - val_loss: 0.2952 - val_acc: 0.9169\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2672 - acc: 0.9256 - val_loss: 0.2502 - val_acc: 0.9312\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2383 - acc: 0.9338 - val_loss: 0.2299 - val_acc: 0.9370\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2150 - acc: 0.9410 - val_loss: 0.2077 - val_acc: 0.9427\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1953 - acc: 0.9459 - val_loss: 0.1967 - val_acc: 0.9461\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1799 - acc: 0.9501 - val_loss: 0.1836 - val_acc: 0.9469\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1662 - acc: 0.9537 - val_loss: 0.1741 - val_acc: 0.9515\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1549 - acc: 0.9563 - val_loss: 0.1624 - val_acc: 0.9540\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1448 - acc: 0.9596 - val_loss: 0.1582 - val_acc: 0.9542\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1362 - acc: 0.9618 - val_loss: 0.1491 - val_acc: 0.9579\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1291 - acc: 0.9630 - val_loss: 0.1439 - val_acc: 0.9581\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1219 - acc: 0.9650 - val_loss: 0.1416 - val_acc: 0.9570\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1160 - acc: 0.9663 - val_loss: 0.1460 - val_acc: 0.9579\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1096 - acc: 0.9689 - val_loss: 0.1321 - val_acc: 0.9604\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1053 - acc: 0.9700 - val_loss: 0.1292 - val_acc: 0.9615\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1006 - acc: 0.9708 - val_loss: 0.1363 - val_acc: 0.9609\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0967 - acc: 0.9725 - val_loss: 0.1252 - val_acc: 0.9638\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0924 - acc: 0.9739 - val_loss: 0.1239 - val_acc: 0.9635\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0883 - acc: 0.9754 - val_loss: 0.1259 - val_acc: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4af63abb38>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(x_train, y_train, batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(784,), activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_normal\")`\n",
      "  import sys\n",
      "C:\\Users\\Avsenin.Pavel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.7260 - acc: 0.8164 - val_loss: 0.3879 - val_acc: 0.8942\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.3519 - acc: 0.9012 - val_loss: 0.3036 - val_acc: 0.9126\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2943 - acc: 0.9147 - val_loss: 0.2682 - val_acc: 0.9232\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2616 - acc: 0.9237 - val_loss: 0.2421 - val_acc: 0.9294\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2375 - acc: 0.9302 - val_loss: 0.2227 - val_acc: 0.9345\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2176 - acc: 0.9363 - val_loss: 0.2082 - val_acc: 0.9392\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2002 - acc: 0.9413 - val_loss: 0.1923 - val_acc: 0.9419\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1848 - acc: 0.9462 - val_loss: 0.1798 - val_acc: 0.9454\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1717 - acc: 0.9505 - val_loss: 0.1737 - val_acc: 0.9476\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1601 - acc: 0.9534 - val_loss: 0.1594 - val_acc: 0.9519\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1497 - acc: 0.9567 - val_loss: 0.1504 - val_acc: 0.9553\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1401 - acc: 0.9594 - val_loss: 0.1439 - val_acc: 0.9566\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1318 - acc: 0.9619 - val_loss: 0.1377 - val_acc: 0.9595\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1241 - acc: 0.9644 - val_loss: 0.1315 - val_acc: 0.9603\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1174 - acc: 0.9662 - val_loss: 0.1275 - val_acc: 0.9612\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1113 - acc: 0.9679 - val_loss: 0.1200 - val_acc: 0.9630\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1054 - acc: 0.9697 - val_loss: 0.1173 - val_acc: 0.9640\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1004 - acc: 0.9714 - val_loss: 0.1141 - val_acc: 0.9656\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0956 - acc: 0.9725 - val_loss: 0.1111 - val_acc: 0.9653\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0911 - acc: 0.9743 - val_loss: 0.1072 - val_acc: 0.9656\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0868 - acc: 0.9755 - val_loss: 0.1064 - val_acc: 0.9655\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0832 - acc: 0.9767 - val_loss: 0.1022 - val_acc: 0.9677\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0795 - acc: 0.9772 - val_loss: 0.1001 - val_acc: 0.9684\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0760 - acc: 0.9781 - val_loss: 0.0988 - val_acc: 0.9689\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0732 - acc: 0.9790 - val_loss: 0.0958 - val_acc: 0.9684\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0702 - acc: 0.9800 - val_loss: 0.0945 - val_acc: 0.9700\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0669 - acc: 0.9809 - val_loss: 0.0927 - val_acc: 0.9702\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0645 - acc: 0.9817 - val_loss: 0.0922 - val_acc: 0.9707\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0619 - acc: 0.9825 - val_loss: 0.0905 - val_acc: 0.9710\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0594 - acc: 0.9834 - val_loss: 0.0879 - val_acc: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4a993c6dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(x_train, y_train, batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель используя инициализацию Хе для начальных весов нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "def fullyconnected_layer(tensor, input_size, out_size):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, out_size], stddev=0.1))\n",
    "    b = tf.Variable(tf.truncated_normal([out_size], stddev=0.1))\n",
    "    return tf.nn.tanh(tf.matmul(tensor, W) + b)\n",
    "\n",
    "def batchnorm_layer(tensor, size):\n",
    "    batch_mean, batch_var = tf.nn.moments(tensor, [0])\n",
    "    beta = tf.Variable(tf.zeros([size]))\n",
    "    scale = tf.Variable(tf.ones([size]))\n",
    "    return tf.nn.batch_normalization(tensor, batch_mean, batch_var, beta, scale, 0.001)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "h1 = fullyconnected_layer(x, 784, 100)\n",
    "h1_bn = batchnorm_layer(h1, 100)\n",
    "h2 = fullyconnected_layer(h1_bn, 100, 100)\n",
    "y_logit = fullyconnected_layer(h2, 100, 10)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(y_logit, y)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.955\n"
     ]
    }
   ],
   "source": [
    "# Обучите заданную многослойную сеть на тренировочном наборе и посчитайте точность на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте точность для любого адаптивного варианта градиентного спуска"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
